{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai.vision.all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c7dc0706fd8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maugmenters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0miaa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai.vision.all'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "import cv2\n",
    "from builtins import range\n",
    "from skimage.io import imread\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import applications, backend, callbacks, layers\n",
    "from tensorflow.keras import models, metrics, optimizers, preprocessing\n",
    "from tensorflow.keras import regularizers, utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed randomness for reproducibility\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "rs = np.random.RandomState(np.random.MT19937(np.random.SeedSequence(SEED)))\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 3\n",
    "PATIENCE = 4\n",
    "BATCH_SIZE = 50\n",
    "VALIDATION_FRAC = 0.30\n",
    "INIT_LEARN_RATE = 0.01\n",
    "FREEZE_LAYERS_FRAC = 0.94\n",
    "\n",
    "# Inputs \n",
    "COLOR_MODE = 'grayscale'\n",
    "INTERPOLATION = 'hamming'\n",
    "\n",
    "TRAIN_DOWNSAMPLE_FRAC = 1.00\n",
    "\n",
    "SCALE_DIM = 2 # Tested 1-7\n",
    "XCEPT_DIM = 299\n",
    "IMAGE_SIZE = (SCALE_DIM * XCEPT_DIM,\n",
    "              SCALE_DIM * XCEPT_DIM)\n",
    "IMAGE_SHAPE = IMAGE_SIZE + (1,)\n",
    "\n",
    "\n",
    "# Classes\n",
    "CLASS_H = 'Healthy'\n",
    "CLASS_VPNA = 'Viral PNA'\n",
    "CLASS_BPNA = 'Bacterial PNA'\n",
    "\n",
    "# Stages\n",
    "STAGE_TRAIN = 'train'\n",
    "STAGE_VAL = 'val'\n",
    "STAGE_TEST = 'test'\n",
    "\n",
    "# Pathing\n",
    "DATA_PATH = '../dataset'\n",
    "# DATA_PATHCNN = Path('C:\\\\Users\\\\donquijote\\\\Desktop\\\\IA\\\\zoidberg_2020_15\\\\project\\\\dataset\\\\'); path.ls()\n",
    "# Logging\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above constants are used throughout the report. They are applied as the base value for all algorithms, but may be updated for the specific case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>stage</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../dataset/train/PNEUMONIA/person1000_bacteria...</td>\n",
       "      <td>1152</td>\n",
       "      <td>760</td>\n",
       "      <td>train</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../dataset/train/PNEUMONIA/person1000_virus_16...</td>\n",
       "      <td>1072</td>\n",
       "      <td>768</td>\n",
       "      <td>train</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../dataset/train/PNEUMONIA/person1001_bacteria...</td>\n",
       "      <td>1244</td>\n",
       "      <td>863</td>\n",
       "      <td>train</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../dataset/train/PNEUMONIA/person1002_bacteria...</td>\n",
       "      <td>1242</td>\n",
       "      <td>940</td>\n",
       "      <td>train</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../dataset/train/PNEUMONIA/person1003_bacteria...</td>\n",
       "      <td>1488</td>\n",
       "      <td>1280</td>\n",
       "      <td>train</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  width  height  stage  \\\n",
       "0  ../dataset/train/PNEUMONIA/person1000_bacteria...   1152     760  train   \n",
       "1  ../dataset/train/PNEUMONIA/person1000_virus_16...   1072     768  train   \n",
       "2  ../dataset/train/PNEUMONIA/person1001_bacteria...   1244     863  train   \n",
       "3  ../dataset/train/PNEUMONIA/person1002_bacteria...   1242     940  train   \n",
       "4  ../dataset/train/PNEUMONIA/person1003_bacteria...   1488    1280  train   \n",
       "\n",
       "       class  \n",
       "0  PNEUMONIA  \n",
       "1  PNEUMONIA  \n",
       "2  PNEUMONIA  \n",
       "3  PNEUMONIA  \n",
       "4  PNEUMONIA  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gather_files_into_dataframe(path):\n",
    "  \n",
    "    frames = []\n",
    "\n",
    "    for stage in (STAGE_TRAIN, STAGE_VAL, STAGE_TEST):\n",
    "\n",
    "        for target in ('PNEUMONIA', 'NORMAL'):\n",
    "\n",
    "            # Gather and sort file names\n",
    "            filenames = pd.Series(glob.glob(os.path.join(\n",
    "              path, '', stage, target, '*.jpeg')))\n",
    "            filenames.sort_values(inplace=True)\n",
    "\n",
    "            # Gather image dimensions\n",
    "            widths, heights = zip(*[Image.open(filename).size \n",
    "                                    for filename in filenames])\n",
    "\n",
    "            frames.append(pd.DataFrame({'filename': filenames,\n",
    "                                      'width': widths,\n",
    "                                      'height': heights,\n",
    "                                      'stage': stage,\n",
    "                                      'class': target}))\n",
    "\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "df = gather_files_into_dataframe(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are initially stored in a panda dataframe from ease of access and customizability. This way the train, test and validate data can be stored in the same object and easily managed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network \n",
    "\n",
    "With the CNN, we can't use the same function to pre-process the dataset\n",
    "to use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fastai.vision' has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b8d0356e8f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data = fastai.vision.all.DataBlock(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoryBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mget_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_image_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_pct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mget_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fastai.vision' has no attribute 'all'"
     ]
    }
   ],
   "source": [
    "data = fastai.vision.all.DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128))\n",
    "\n",
    "dls = data.dataloaders(path)\n",
    "print(\"We can see all picture from the dataset\")\n",
    "dls.valid.show_batch(max_n=20, nrows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=[error_rate,accuracy])\n",
    "learn.fine_tune(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save the model to keep it.\n",
    "To have a better understanding of the result we do a confusion matrix to be able to see true positive and false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model_1')\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize of the view\n",
    "For having an other visual, we do a confusion matrix with percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(normalize=True, norm_dec=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can see the total amount of False Positive\n",
    "### Show in a line the misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual of losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(3, nrows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph for the Learning Rate vs Loss\n",
    "\n",
    "With the method of step by step and a learning rate increasing, we can see that the loss is decreasing fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min,lr_steep = learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement of our algorithm CNN\n",
    "\n",
    "To see if we can improve our model, we will try to play a bit with some variable like epoch or learning rate with some iteration.\n",
    "\n",
    "We will use a method call unfreezing that will keep the model to find a learning rate for use the max in a new epoch to see if anything change\n",
    "\n",
    "We trying to modify the step of learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=[error_rate,accuracy])\n",
    "learn.fine_tune(EPOCHS, base_lr=5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More let's try the unfreeze method with many cycle\n",
    "\n",
    "### Discriminative Learning Rates & Unfreezing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=[error_rate,accuracy])\n",
    "learn.fit_one_cycle(EPOCHS, 5e-3)\n",
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.fit_one_cycle(EPOCHS, lr_max=slice(5e-3,1e-3))\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "\n",
    "As we can see, there no big difference with the first test we ran. The unfreeze method doesn't really change many thing, the actual purpose of this is to prevents the weights of a neural network layer from being modified during the backward pass of training. It helps to decrease training time.\n",
    "\n",
    "The very good thing, is that we can stop the model, and then use it with an other dataset to improve the accurency.\n",
    "When you choose to freeze is a balance between freezing early enough to gain computational speed-up without freezing too early with weights that result in inaccurate predictions.\n",
    "\n",
    "The accurency with CNN is very good. And the train loss and valid loss is decreasing pretty fast. Who give a very low amount of true negatives. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(64, 64)):\n",
    "    \"\"\"\n",
    "    Resize all images to be the same size\n",
    "    \"\"\"\n",
    "    return cv2.resize(image, size).flatten()\n",
    "\n",
    "\n",
    "def extract_color_histogram(image, bins=(40, 40, 40)):\n",
    "    \"\"\"\n",
    "    extract a 3D color histogram from the HSV color space using\n",
    "    the supplied number of `bins` per channel\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "        [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()\n",
    "\n",
    "def get_images(image_paths):\n",
    "    \"\"\"\n",
    "    take an array of images paths and return the raw images,\n",
    "    histograms and labels for each image, in a numpy array\n",
    "    \"\"\"\n",
    "    rawImages = []\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for (i, imagePath) in enumerate(image_paths):\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        file = imagePath.split(os.path.sep)[-1]\n",
    "        image = cv2.imread(imagePath) #sets image to BGR\n",
    "        images_aug = seq.augment_image(image)\n",
    "        pixels = image_to_feature_vector(images_aug)\n",
    "        hist = extract_color_histogram(images_aug)    \n",
    "        rawImages.append(pixels)\n",
    "        features.append(hist)\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "        if i > 0 and i % 500 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(image_paths)))\n",
    "    \n",
    "    return rawImages, features, labels\n",
    "\n",
    "\n",
    "# Data augmentation\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and training data\n",
    "df_test = df.loc[df['stage'] == STAGE_TEST]\n",
    "df_train = df.loc[df['stage'] == STAGE_TRAIN]\n",
    "trainRI, trainFeat, trainLabels = get_images(df_train['filename'].to_numpy())\n",
    "testRI, testFeat, testLabels = get_images(df_test['filename'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating raw pixel accuracy...\n",
      "[INFO] raw pixel accuracy: 72.60%\n",
      "[INFO] evaluating histogram accuracy...\n",
      "[INFO] histogram accuracy: 75.64%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a k-NN classifer on the raw pixel intensities\n",
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "ri_model = KNeighborsClassifier(n_neighbors=8)\n",
    "ri_model.fit(trainRI, trainLabels)\n",
    "ri_acc = ri_model.score(testRI, testLabels)\n",
    "print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(ri_acc * 100))\n",
    "\n",
    "# train and evaluate a k-NN classifer on the histogram\n",
    "# representations\n",
    "print(\"[INFO] evaluating histogram accuracy...\")\n",
    "fea_model = KNeighborsClassifier(n_neighbors=8)\n",
    "fea_model.fit(trainFeat, trainLabels)\n",
    "fea_acc = fea_model.score(testFeat, testLabels)\n",
    "print(\"[INFO] histogram accuracy: {:.2f}%\".format(fea_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two models were created to compare the results between raw images and histograms. Both types were extracted using the OpenCV library and flattedned to 1D arrays. \n",
    "\n",
    "Raw images were all set to the square size of 64x64, and the 3D histograms were created with 40 bins in the HSV colour space, normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Normal  Pneumonia\n",
      "Normal        131        103\n",
      "Pneumonia      49        341\n",
      "           Normal  Pneumonia\n",
      "Normal         68        166\n",
      "Pneumonia       5        385\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.73      0.56      0.63       234\n",
      "   PNEUMONIA       0.77      0.87      0.82       390\n",
      "\n",
      "    accuracy                           0.76       624\n",
      "   macro avg       0.75      0.72      0.73       624\n",
      "weighted avg       0.75      0.76      0.75       624\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.93      0.29      0.44       234\n",
      "   PNEUMONIA       0.70      0.99      0.82       390\n",
      "\n",
      "    accuracy                           0.73       624\n",
      "   macro avg       0.82      0.64      0.63       624\n",
      "weighted avg       0.79      0.73      0.68       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "cm = metrics.confusion_matrix(testLabels, fea_model.predict(testFeat))\n",
    "data = {\n",
    "    \"Normal\": [cm[0][0], cm[1][0]],\n",
    "    \"Pneumonia\": [cm[0][1], cm[1][1]]\n",
    "}\n",
    "df_feat = pd.DataFrame(data, index=[\"Normal\", \"Pneumonia\"])\n",
    "print(df_feat)\n",
    "cm = metrics.confusion_matrix(testLabels, ri_model.predict(testRI))\n",
    "data = {\n",
    "    \"Normal\": [cm[0][0], cm[1][0]],\n",
    "    \"Pneumonia\": [cm[0][1], cm[1][1]]\n",
    "}\n",
    "df_ri = pd.DataFrame(data, index=[\"Normal\", \"Pneumonia\"])\n",
    "print(df_ri)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(testLabels, fea_model.predict(testFeat)))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(testLabels, ri_model.predict(testRI)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After accuracies were calculated, the confusion matrices, precision, recall, f1-score and support were calculated and compared to determine the most effective image data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 500/5856\n",
      "[INFO] processed 1000/5856\n",
      "[INFO] processed 1500/5856\n",
      "[INFO] processed 2000/5856\n",
      "[INFO] processed 2500/5856\n",
      "[INFO] processed 3000/5856\n",
      "[INFO] processed 3500/5856\n",
      "[INFO] processed 4000/5856\n",
      "[INFO] processed 4500/5856\n",
      "[INFO] processed 5000/5856\n",
      "[INFO] processed 5500/5856\n",
      "X shape: (5856, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_images_svm(image_paths):\n",
    "    \"\"\"\n",
    "    take an array of images paths and return the raw images,\n",
    "    histograms and labels for each image, in a numpy array\n",
    "    \"\"\"\n",
    "    train_img = []\n",
    "\n",
    "    for (i, imagePath) in enumerate(image_paths):\n",
    "        img = cv2.imread(imagePath) #sets image to BGR\n",
    "        img = seq.augment_image(img)\n",
    "        img = np.squeeze(img)\n",
    "        img_pred = cv2.resize(img, (50, 50), interpolation=cv2.INTER_AREA)\n",
    "        img_pred = img_pred[:, :]\n",
    "        img_pred = image.img_to_array(img_pred)\n",
    "        img_pred = img_pred / 255\n",
    "\n",
    "        train_img.append(img_pred)\n",
    "\n",
    "        if i > 0 and i % 500 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(image_paths)))\n",
    "    \n",
    "    X = np.array(train_img)\n",
    "    return X\n",
    "\n",
    "\n",
    "# Data augmentation\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
    "])\n",
    "\n",
    "labels = []\n",
    "labelCounts = [0,0]\n",
    "\n",
    "\n",
    "X0 = get_images_svm(df['filename'].to_numpy())\n",
    "X = np.zeros((5856, 50, 50, 3))\n",
    "X[:, :, :, 0] = X0[:, :, :, 0]\n",
    "X[:, :, :, 1] = X0[:, :, :, 0]\n",
    "X[:, :, :, 2] = X0[:, :, :, 0]\n",
    "\n",
    "\n",
    "\n",
    "print(\"X shape: \"+str(X.shape))\n",
    "\n",
    "y0 = np.zeros(5216)\n",
    "y1 = np.ones(640)\n",
    "# concatenate y0 and y1 to form y\n",
    "y = []\n",
    "y = np.concatenate((y0, y1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SVM, images were loaded in a slightly different way to take into account the colour channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (4684, 50, 50, 3)\n",
      "X_test: (586, 50, 50, 3)\n",
      "X_val: (586, 50, 50, 3)\n",
      "y_train: (4684,)\n",
      "y_test: (586,)\n",
      "y_val: (586,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.20)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, random_state=42, test_size=0.5)\n",
    "print(\"X_train: \" + str(X_train.shape))\n",
    "print(\"X_test: \" + str(X_test.shape))\n",
    "print(\"X_val: \" + str(X_val.shape))\n",
    "print(\"y_train: \" + str(y_train.shape))\n",
    "print(\"y_test: \" + str(y_test.shape))\n",
    "print(\"y_val: \" + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4684, 7500) (586, 7500) (586, 7500)\n",
      "(4684,) (586,) (586,)\n"
     ]
    }
   ],
   "source": [
    "# take only the length of the 1st dimension for each\n",
    "num_training = X_train.shape[0]\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "num_test = X_test.shape[0]\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "num_val = X_val.shape[0]\n",
    "mask = list(range(num_val))\n",
    "X_val = X_val[mask]\n",
    "y_val = y_val[mask]\n",
    "\n",
    "# Reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "print(y_train.shape, y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4684, 7501) (586, 7501) (586, 7501)\n",
      "Data ready\n"
     ]
    }
   ],
   "source": [
    "# Getting data to zero mean, i.e centred around zero.\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image\n",
    "X_val -= mean_image\n",
    "# append the bias dimension of ones (i.e. bias trick) so that our SVM\n",
    "# only has to worry about optimizing a single weight matrix W.\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "print(\"Data ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from builtins import object\n",
    "# for svm_loss_vectorized\n",
    "\n",
    "def svm_loss_vectorized(W, X, y, reg):\n",
    "    loss = 0.0\n",
    "    dW = np.zeros(W.shape)  # initialize the gradient as zero\n",
    "    num_classes = W.shape[1]\n",
    "    num_train = X.shape[0]\n",
    "    scores = X.dot(W)\n",
    "    y = [int(x) for x in y]\n",
    "    correct_class_scores = scores[np.arange(num_train), y].reshape(num_train, 1)\n",
    "    margin = np.maximum(0, scores - correct_class_scores + 1)\n",
    "    margin[np.arange(num_train), y] = 0  # do not consider correct class in loss\n",
    "    loss = margin.sum() / num_train\n",
    "    # Add regularization to the loss.\n",
    "    loss += reg * np.sum(W * W)\n",
    "\n",
    "    margin[margin > 0] = 1\n",
    "    valid_margin = margin.sum(axis=1)\n",
    "    margin[np.arange(num_train), y] -= valid_margin\n",
    "    dW = (X.T).dot(margin) / num_train\n",
    "    # dW /= num_train\n",
    "    # Regularization gradient\n",
    "    dW = dW + reg * 2 * W\n",
    "    return loss, dW\n",
    "\n",
    "\n",
    "class LinearClassifier(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "\n",
    "    def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
    "              batch_size=200, verbose=False):\n",
    "\n",
    "        num_train, dim = X.shape\n",
    "        num_classes = np.max(y) + 1 # assume y takes values 0...K-1 where K is number of classes\n",
    "        if self.W is None:\n",
    "            self.W = 0.001 * np.random.randn(dim, int(num_classes))\n",
    "        # Run stochastic gradient descent to optimize W\n",
    "        loss_history = []\n",
    "        for it in range(num_iters):\n",
    "            X_batch = None\n",
    "            y_batch = None\n",
    "\n",
    "            batch_indices = np.random.choice(num_train, batch_size, replace=False)\n",
    "            X_batch = X[batch_indices]\n",
    "            y_batch=y[batch_indices]\n",
    "\n",
    "            # evaluate loss and gradient\n",
    "            loss, grad = self.loss(X_batch, y_batch, reg)\n",
    "            loss_history.append(loss)\n",
    "\n",
    "            # Update the weights using the gradient and the learning rate.          #\n",
    "\n",
    "            self.W -= learning_rate*grad\n",
    "\n",
    "            if verbose and it % 100 == 0:\n",
    "                print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
    "\n",
    "        return loss_history\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained weights of this linear classifier to predict labels for\n",
    "        data points.\n",
    "        \"\"\"\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        scores = X.dot(self.W)\n",
    "        y_pred = scores.argmax(axis=1)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class LinearSVM(LinearClassifier):\n",
    "    \"\"\" A subclass that uses the Multiclass SVM loss function \"\"\"\n",
    "\n",
    "    def loss(self, X_batch, y_batch, reg):\n",
    "        return svm_loss_vectorized(self.W, X_batch, y_batch, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.701110\n",
      "validation accuracy: 0.682594\n"
     ]
    }
   ],
   "source": [
    "svmd = LinearSVM()\n",
    "loss_hist = svmd.train(X_train, y_train, learning_rate=1e-7, reg=2.5e4, num_iters=1500, verbose=False)\n",
    "\n",
    "y_train_pred = svmd.predict(X_train)\n",
    "print('training accuracy: %f' % (np.mean(y_train == y_train_pred),))\n",
    "y_val_pred = svmd.predict(X_val)\n",
    "print('validation accuracy: %f' % (np.mean(y_val == y_val_pred),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa2f2b74290>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred_keras = svmd.predict(X_test).ravel()\n",
    "print(y_pred_keras.shape)\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n",
    "\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "# plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
